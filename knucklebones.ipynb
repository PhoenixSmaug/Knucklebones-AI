{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Knucklebones AI\n",
    "\n",
    "Knucklebones is a highly random dice game developed by the studio [Massive Monster](https://massivemonster.co) available to play online [here](https://knucklebones.io). There you can also find a summary of the rules of the game; a more detailed explanation also given on the [Fandom Wiki](https://cult-of-the-lamb.fandom.com/wiki/Knucklebones). The goal of this project was to train an AI for Knucklebones by self play using the Reinforcement Learning library [Stable-Baselines3](https://stable-baselines3.readthedocs.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by modelling the game according to OpenAI's Gym Standard for Reinforcement Learning. The RL model will provide a ranking of its preferences for the three options (encoded as one of the 6 permutations) and the game will chooses the valid actions with the highest preference. This prevents the AI from making invalid actions, so placing a dice in an already full column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnucklebonesEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(KnucklebonesEnv, self).__init__()\n",
    "        self.board = np.zeros((2, 3, 3), dtype=int)\n",
    "        self.current_player = 0\n",
    "        self.current_dice = None\n",
    "\n",
    "        # action indicates preferences between three columns encoded as permutation\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(low=0, high=6, shape=(19,), dtype=np.int32)\n",
    "\n",
    "        # Define the permutations\n",
    "        self.permutations = [\n",
    "            [0, 1, 2],\n",
    "            [0, 2, 1],\n",
    "            [1, 0, 2],\n",
    "            [1, 2, 0],\n",
    "            [2, 0, 1],\n",
    "            [2, 1, 0]\n",
    "        ]\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.board = np.zeros((2, 3, 3), dtype=int)\n",
    "        self.current_player = 0\n",
    "        self.current_dice = self.roll_dice()\n",
    "        return self.get_observation(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Convert the action to a permutation\n",
    "        column_order = self.permutations[action]\n",
    "\n",
    "        for column in column_order:\n",
    "            if self.is_valid_action(column):\n",
    "                self.place_dice(self.current_player, column, self.current_dice)\n",
    "                self.remove_opponent_dice(1 - self.current_player, column, self.current_dice)\n",
    "                break\n",
    "\n",
    "        terminated = self.is_game_over()\n",
    "        reward = self.calculate_score(self.current_player)\n",
    "        \n",
    "        self.current_player = 1 - self.current_player\n",
    "        self.current_dice = self.roll_dice()\n",
    "\n",
    "        return self.get_observation(), float(reward), bool(terminated), False, {}\n",
    "\n",
    "    def roll_dice(self):\n",
    "        return self.np_random.integers(1, 7)\n",
    "\n",
    "    def is_valid_action(self, action):\n",
    "        return 0 <= action < 3 and np.any(self.board[self.current_player, action] == 0)\n",
    "\n",
    "    def place_dice(self, player, column, value):\n",
    "        empty_spots = np.where(self.board[player, column] == 0)[0]\n",
    "        if empty_spots.size > 0:\n",
    "            self.board[player, column, empty_spots[0]] = value\n",
    "\n",
    "    def remove_opponent_dice(self, opponent, column, value):\n",
    "        self.board[opponent, column] = np.where(self.board[opponent, column] == value, 0, self.board[opponent, column])\n",
    "        self.board[opponent, column] = np.sort(self.board[opponent, column])[::-1]\n",
    "\n",
    "    def is_game_over(self):\n",
    "        return np.all(self.board[0] != 0) or np.all(self.board[1] != 0)\n",
    "\n",
    "    def calculate_score(self, player):\n",
    "        score = 0\n",
    "        for column in self.board[player]:\n",
    "            unique, counts = np.unique(column[column != 0], return_counts=True)\n",
    "            for value, count in zip(unique, counts):\n",
    "                score += value * count\n",
    "        return score\n",
    "\n",
    "    def get_observation(self):\n",
    "        return np.concatenate([self.board.flatten(), [self.current_dice]]).astype(np.int32)\n",
    "\n",
    "    def render(self):\n",
    "        for player in range(2):\n",
    "            print(f\"Player {player + 1}:\")\n",
    "            for row in range(3):\n",
    "                print(\" \".join(f\"{self.board[player, col, row]:2d}\" for col in range(3)))\n",
    "            print()\n",
    "        print(f\"Current player: {self.current_player + 1}, Current dice: {self.current_dice}\")\n",
    "\n",
    "    def get_current_player(self):\n",
    "        return self.current_player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be trained using self-play, so by adversarial playing against itself across thousands of games. Since Stable-Baselines3 does not have native support for environments with multiple agents, we wrap the game environment in a multienvironment containing a separate opponent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnucklebonesMultiEnv(KnucklebonesEnv):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.player_1_obs = None\n",
    "        self.player_2_obs = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        obs, info = super().reset(seed=seed, options=options)\n",
    "        self.player_1_obs = obs\n",
    "        self.player_2_obs = self._flip_observation(obs)\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "        self.player_1_obs = obs if self.current_player == 0 else self._flip_observation(obs)\n",
    "        self.player_2_obs = obs if self.current_player == 1 else self._flip_observation(obs)\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def _flip_observation(self, obs):\n",
    "        flipped_obs = obs.copy()\n",
    "        flipped_obs[:9], flipped_obs[9:18] = obs[9:18], obs[:9]\n",
    "        return flipped_obs\n",
    "\n",
    "    def get_player_obs(self, player):\n",
    "        return self.player_1_obs if player == 0 else self.player_2_obs\n",
    "\n",
    "class SelfPlayEnv(gym.Env):\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.opponent = None\n",
    "        self.action_space = env.action_space\n",
    "        self.observation_space = env.observation_space\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        return self.env.reset(seed=seed, options=options)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        if not done:\n",
    "            if self.opponent:\n",
    "                opponent_obs = self.env.get_player_obs(self.env.get_current_player())\n",
    "                opponent_action, _ = self.opponent.predict(opponent_obs, deterministic=True)\n",
    "                obs, reward_op, done, truncated, info = self.env.step(opponent_action)\n",
    "                # reward as difference to opponent score\n",
    "                reward -= reward_op\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def set_opponent(self, opponent):\n",
    "        self.opponent = opponent\n",
    "\n",
    "    def render(self):\n",
    "        return self.env.render()\n",
    "\n",
    "env = KnucklebonesMultiEnv()\n",
    "# check that environment is compatible with the OpenAI gym standard\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reward function we will use the difference between the score of the model player and the score of the opponent in the next round. The aim is to encourage the model to maximize its own score but also prevent the opponent from achieving a high score. Now we need a function to evaluate two models playing against each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_example_game(env, model_1=None, model_2=None, render: bool = True):\n",
    "    obs, _ = env.reset()\n",
    "    terminated = False\n",
    "    max_steps = 100\n",
    "    player_scores = [0, 0]\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        if render:\n",
    "            env.render()\n",
    "\n",
    "        current_player = env.get_current_player()\n",
    "        current_obs = env.get_player_obs(current_player)\n",
    "\n",
    "        if current_player == 0:\n",
    "            action = model_1.predict(current_obs, deterministic=True)[0] if model_1 else env.action_space.sample()\n",
    "        else:\n",
    "            action = model_2.predict(current_obs, deterministic=True)[0] if model_2 else env.action_space.sample()\n",
    "\n",
    "        obs, reward, terminated, _, _ = env.step(action)\n",
    "        player_scores[current_player] = env.calculate_score(current_player)\n",
    "        \n",
    "        if render:\n",
    "            print(f\"Player {current_player + 1} Action: {action}\")\n",
    "            print(f\"Action permutation: {env.permutations[action]}\")\n",
    "            print(f\"Player 1 Score: {player_scores[0]}, Player 2 Score: {player_scores[1]}\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        if terminated:\n",
    "            break\n",
    "\n",
    "    if render:\n",
    "        env.render()\n",
    "        print(f\"Game Over. Final Scores - Player 1: {player_scores[0]}, Player 2: {player_scores[1]}\")\n",
    "    \n",
    "    return player_scores[0] - player_scores[1]  # Return the score difference\n",
    "\n",
    "def evaluate_models(env, model_1, model_2, n_games: int = 1000):\n",
    "    model_1_wins = 0\n",
    "    model_2_wins = 0\n",
    "    draws = 0\n",
    "\n",
    "    for _ in range(n_games):\n",
    "        reward = play_example_game(env, model_1, model_2, render=False)\n",
    "        if reward > 0:\n",
    "            model_1_wins += 1\n",
    "        elif reward < 0:\n",
    "            model_2_wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    print(f\"Model 1 wins: {model_1_wins}\")\n",
    "    print(f\"Model 2 wins: {model_2_wins}\")\n",
    "    print(f\"Draws: {draws}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that our game implementation is working correctly, we can have a look at an example game between models making uniformly random actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 6\n",
      "Player 1 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 6, Player 2 Score: 0\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  0  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 5\n",
      "Player 2 Action: 1\n",
      "Action permutation: [0, 2, 1]\n",
      "Player 1 Score: 6, Player 2 Score: 5\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  0  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 5  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 4\n",
      "Player 1 Action: 2\n",
      "Action permutation: [1, 0, 2]\n",
      "Player 1 Score: 10, Player 2 Score: 5\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 5  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 4\n",
      "Player 2 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 10, Player 2 Score: 9\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 5  0  0\n",
      " 4  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 4\n",
      "Player 1 Action: 2\n",
      "Action permutation: [1, 0, 2]\n",
      "Player 1 Score: 14, Player 2 Score: 9\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  4  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 5  0  0\n",
      " 4  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 6\n",
      "Player 2 Action: 1\n",
      "Action permutation: [0, 2, 1]\n",
      "Player 1 Score: 14, Player 2 Score: 15\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  4  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 5  0  0\n",
      " 4  0  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 1, Current dice: 2\n",
      "Player 1 Action: 2\n",
      "Action permutation: [1, 0, 2]\n",
      "Player 1 Score: 16, Player 2 Score: 15\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  4  0\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 5  0  0\n",
      " 4  0  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 2, Current dice: 5\n",
      "Player 2 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 16, Player 2 Score: 20\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  4  0\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 5  5  0\n",
      " 4  0  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 1, Current dice: 5\n",
      "Player 1 Action: 3\n",
      "Action permutation: [1, 2, 0]\n",
      "Player 1 Score: 21, Player 2 Score: 20\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  4  5\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 5  5  0\n",
      " 4  0  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 2, Current dice: 1\n",
      "Player 2 Action: 3\n",
      "Action permutation: [1, 2, 0]\n",
      "Player 1 Score: 21, Player 2 Score: 21\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  4  5\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 5  5  0\n",
      " 4  1  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 1, Current dice: 3\n",
      "Player 1 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 24, Player 2 Score: 21\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  6\n",
      " 0  4  5\n",
      " 0  2  3\n",
      "\n",
      "Player 2:\n",
      " 5  5  0\n",
      " 4  1  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 2, Current dice: 6\n",
      "Player 2 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 24, Player 2 Score: 27\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  5\n",
      " 0  4  3\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 5  5  6\n",
      " 4  1  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 1, Current dice: 4\n",
      "Player 1 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 22, Player 2 Score: 27\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  5\n",
      " 0  4  3\n",
      " 0  2  4\n",
      "\n",
      "Player 2:\n",
      " 5  5  6\n",
      " 4  1  0\n",
      " 6  0  0\n",
      "\n",
      "Current player: 2, Current dice: 1\n",
      "Player 2 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 22, Player 2 Score: 28\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  4  5\n",
      " 0  4  4\n",
      " 0  2  3\n",
      "\n",
      "Player 2:\n",
      " 5  5  6\n",
      " 4  1  1\n",
      " 6  0  0\n",
      "\n",
      "Current player: 1, Current dice: 5\n",
      "Player 1 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 27, Player 2 Score: 28\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 5  4  5\n",
      " 0  4  4\n",
      " 0  2  3\n",
      "\n",
      "Player 2:\n",
      " 6  5  6\n",
      " 4  1  1\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 5\n",
      "Player 2 Action: 4\n",
      "Action permutation: [2, 0, 1]\n",
      "Player 1 Score: 27, Player 2 Score: 28\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 5  4  4\n",
      " 0  4  3\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 6  5  6\n",
      " 4  1  1\n",
      " 0  0  5\n",
      "\n",
      "Current player: 1, Current dice: 6\n",
      "Player 1 Action: 1\n",
      "Action permutation: [0, 2, 1]\n",
      "Player 1 Score: 28, Player 2 Score: 28\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 5  4  4\n",
      " 6  4  3\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  5  6\n",
      " 0  1  1\n",
      " 0  0  5\n",
      "\n",
      "Current player: 2, Current dice: 2\n",
      "Player 2 Action: 1\n",
      "Action permutation: [0, 2, 1]\n",
      "Player 1 Score: 28, Player 2 Score: 24\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 6  4  4\n",
      " 5  4  3\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  5  6\n",
      " 2  1  1\n",
      " 0  0  5\n",
      "\n",
      "Current player: 1, Current dice: 1\n",
      "Player 1 Action: 4\n",
      "Action permutation: [2, 0, 1]\n",
      "Player 1 Score: 29, Player 2 Score: 24\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 6  4  4\n",
      " 5  4  3\n",
      " 0  2  1\n",
      "\n",
      "Player 2:\n",
      " 4  5  6\n",
      " 2  1  5\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 6\n",
      "Player 2 Action: 2\n",
      "Action permutation: [1, 0, 2]\n",
      "Player 1 Score: 29, Player 2 Score: 29\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 6  4  4\n",
      " 5  4  3\n",
      " 0  2  1\n",
      "\n",
      "Player 2:\n",
      " 4  5  6\n",
      " 2  1  5\n",
      " 0  6  0\n",
      "\n",
      "Current player: 1, Current dice: 1\n",
      "Player 1 Action: 3\n",
      "Action permutation: [1, 2, 0]\n",
      "Player 1 Score: 30, Player 2 Score: 29\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 6  4  4\n",
      " 5  4  3\n",
      " 1  2  1\n",
      "\n",
      "Player 2:\n",
      " 4  5  6\n",
      " 2  1  5\n",
      " 0  6  0\n",
      "\n",
      "Current player: 2, Current dice: 4\n",
      "Game Over. Final Scores - Player 1: 30, Player 2: 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_example_game(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be trained with proximal policy optimization, a detailed explanation of the mathematical background is given in this [paper](https://arxiv.org/pdf/1707.06347). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(env, model_path: Optional[str] = None) -> PPO:\n",
    "    if model_path:\n",
    "        return PPO.load(model_path, env=env)\n",
    "    return PPO(\"MlpPolicy\", env, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the self play needs to be implemented, where the model is trained across multiple iterations and always playing against the best model from the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_play_training(env, total_timesteps: int = 10**5) -> PPO:\n",
    "    self_play_env = SelfPlayEnv(env)\n",
    "    model = create_model(DummyVecEnv([lambda: self_play_env]))\n",
    "    opponent = None\n",
    "\n",
    "    for i in range(6):  # 6 iterations of self-play\n",
    "        print(f\"Self-play iteration {i+1}\")\n",
    "        \n",
    "        # Set opponent (random for first iteration, previous model for subsequent iterations)\n",
    "        self_play_env.set_opponent(opponent)\n",
    "        \n",
    "        # Train model against opponent\n",
    "        model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "        # Evaluate model against initial opponent\n",
    "        print(\"\\nEvaluating trained model against initial player:\")\n",
    "        evaluate_models(env, model, None)\n",
    "\n",
    "        opponent = model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the actual training process can begin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-play iteration 1\n",
      "\n",
      "Evaluating trained model against initial player:\n",
      "Model 1 wins: 508\n",
      "Model 2 wins: 462\n",
      "Draws: 30\n",
      "\n",
      "Self-play iteration 2\n",
      "\n",
      "Evaluating trained model against initial player:\n",
      "Model 1 wins: 620\n",
      "Model 2 wins: 340\n",
      "Draws: 40\n",
      "\n",
      "Self-play iteration 3\n",
      "\n",
      "Evaluating trained model against initial player:\n",
      "Model 1 wins: 592\n",
      "Model 2 wins: 379\n",
      "Draws: 29\n",
      "\n",
      "Self-play iteration 4\n",
      "\n",
      "Evaluating trained model against initial player:\n",
      "Model 1 wins: 623\n",
      "Model 2 wins: 343\n",
      "Draws: 34\n",
      "\n",
      "Self-play iteration 5\n",
      "\n",
      "Evaluating trained model against initial player:\n",
      "Model 1 wins: 600\n",
      "Model 2 wins: 371\n",
      "Draws: 29\n",
      "\n",
      "Self-play iteration 6\n",
      "\n",
      "Evaluating trained model against initial player:\n",
      "Model 1 wins: 595\n",
      "Model 2 wins: 370\n",
      "Draws: 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = self_play_training(env)\n",
    "model.save(\"knucklebones_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe how the performance increases in the beginning, but quickly levels off. This is not unexpected for a game which is highly dependent on dice rolls, allowing only a small advantage gain from strategy. Let's watch the trained model play an example game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 6\n",
      "Player 1 Action: 4\n",
      "Action permutation: [2, 0, 1]\n",
      "Player 1 Score: 6, Player 2 Score: 0\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  0  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 6\n",
      "Player 2 Action: 3\n",
      "Action permutation: [1, 2, 0]\n",
      "Player 1 Score: 6, Player 2 Score: 6\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  0  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  6  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 2\n",
      "Player 1 Action: 2\n",
      "Action permutation: [1, 0, 2]\n",
      "Player 1 Score: 8, Player 2 Score: 6\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  2  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  6  0\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 3\n",
      "Player 2 Action: 2\n",
      "Action permutation: [1, 0, 2]\n",
      "Player 1 Score: 8, Player 2 Score: 9\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  2  6\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  6  0\n",
      " 0  3  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 4\n",
      "Player 1 Action: 3\n",
      "Action permutation: [1, 2, 0]\n",
      "Player 1 Score: 12, Player 2 Score: 9\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  2  6\n",
      " 0  4  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 0  6  0\n",
      " 0  3  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 4\n",
      "Player 2 Action: 1\n",
      "Action permutation: [0, 2, 1]\n",
      "Player 1 Score: 12, Player 2 Score: 13\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 0  2  6\n",
      " 0  4  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 4  6  0\n",
      " 0  3  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 2\n",
      "Player 1 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 14, Player 2 Score: 13\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  2  6\n",
      " 0  4  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 4  6  0\n",
      " 0  3  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 3\n",
      "Player 2 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 14, Player 2 Score: 16\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  2  6\n",
      " 0  4  0\n",
      " 0  0  0\n",
      "\n",
      "Player 2:\n",
      " 4  6  3\n",
      " 0  3  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 6\n",
      "Player 1 Action: 3\n",
      "Action permutation: [1, 2, 0]\n",
      "Player 1 Score: 20, Player 2 Score: 16\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  2  6\n",
      " 0  4  0\n",
      " 0  6  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 4\n",
      "Player 2 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 20, Player 2 Score: 14\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  2  6\n",
      " 0  4  0\n",
      " 0  6  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 4  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 1, Current dice: 3\n",
      "Player 1 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 23, Player 2 Score: 14\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  2  6\n",
      " 3  4  0\n",
      " 0  6  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 4  0  0\n",
      " 0  0  0\n",
      "\n",
      "Current player: 2, Current dice: 3\n",
      "Player 2 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 23, Player 2 Score: 17\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  2  6\n",
      " 0  4  0\n",
      " 0  6  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 4  0  0\n",
      " 3  0  0\n",
      "\n",
      "Current player: 1, Current dice: 5\n",
      "Player 1 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 25, Player 2 Score: 17\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  2  6\n",
      " 5  4  0\n",
      " 0  6  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 4  0  0\n",
      " 3  0  0\n",
      "\n",
      "Current player: 2, Current dice: 1\n",
      "Player 2 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 25, Player 2 Score: 18\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  6  6\n",
      " 5  4  0\n",
      " 0  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 4  1  0\n",
      " 3  0  0\n",
      "\n",
      "Current player: 1, Current dice: 6\n",
      "Player 1 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 31, Player 2 Score: 18\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  6  6\n",
      " 5  4  0\n",
      " 6  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 4  1  0\n",
      " 3  0  0\n",
      "\n",
      "Current player: 2, Current dice: 6\n",
      "Player 2 Action: 2\n",
      "Action permutation: [1, 0, 2]\n",
      "Player 1 Score: 31, Player 2 Score: 24\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  4  6\n",
      " 5  2  0\n",
      " 6  0  0\n",
      "\n",
      "Player 2:\n",
      " 4  3  3\n",
      " 4  1  0\n",
      " 3  6  0\n",
      "\n",
      "Current player: 1, Current dice: 2\n",
      "Player 1 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 27, Player 2 Score: 24\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  4  6\n",
      " 5  2  0\n",
      " 6  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  6  3\n",
      " 4  3  0\n",
      " 3  1  0\n",
      "\n",
      "Current player: 2, Current dice: 2\n",
      "Player 2 Action: 5\n",
      "Action permutation: [2, 1, 0]\n",
      "Player 1 Score: 27, Player 2 Score: 26\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  4  6\n",
      " 5  2  0\n",
      " 6  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  6  3\n",
      " 4  3  2\n",
      " 3  1  0\n",
      "\n",
      "Current player: 1, Current dice: 4\n",
      "Player 1 Action: 0\n",
      "Action permutation: [0, 1, 2]\n",
      "Player 1 Score: 31, Player 2 Score: 26\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  4  6\n",
      " 5  2  4\n",
      " 6  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  6  3\n",
      " 4  3  2\n",
      " 3  1  0\n",
      "\n",
      "Current player: 2, Current dice: 3\n",
      "Player 2 Action: 3\n",
      "Action permutation: [1, 2, 0]\n",
      "Player 1 Score: 31, Player 2 Score: 29\n",
      "----------------------------------------\n",
      "Player 1:\n",
      " 2  4  6\n",
      " 5  2  4\n",
      " 6  2  0\n",
      "\n",
      "Player 2:\n",
      " 4  6  3\n",
      " 4  3  2\n",
      " 3  1  3\n",
      "\n",
      "Current player: 1, Current dice: 2\n",
      "Game Over. Final Scores - Player 1: 31, Player 2: 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_example_game(env, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Mia Müßig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
